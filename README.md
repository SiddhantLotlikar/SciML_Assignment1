Problem-1:  Write in 2-D function with more than one minima. Initialize the code from 3 points in the specific domain. Plot the convergence graph of solution for all the
initialization points in the same plot for optimizers like Vanilla gradient descent, Momentum gradient
descent, Nesterov momentum gradient descent, ADAGRAD, RMSPROP, And ADAM .

Problem-2: Convert the given equation as polynomial and find the coefficients of polynomials of 5th
order theoretically and find the coefficients with linear regression as well and print the both coefficients.
Keep the X-domain between (0,1) for training the coefficients.
ğ‘¦ = ğ‘¥ âˆ— sin ğ‘¥ + ğ‘’^ğ‘¥
